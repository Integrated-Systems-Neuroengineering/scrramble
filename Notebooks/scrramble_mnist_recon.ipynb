{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64bfdf3",
   "metadata": {},
   "source": [
    "# Reconstructing MNIST imaged with ScRRAMBLe-CapsNets\n",
    "_Created on 07/24/25_\n",
    "\n",
    "- Building up on the CapsNet approach for MNIST, the goal of this notebook is to verify if images can be reconstructed from capsule outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e428d54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 11:58:40.444635: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753469920.458208 3484422 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753469920.462633 3484422 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753469920.474691 3484422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753469920.474706 3484422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753469920.474708 3484422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753469920.474710 3484422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import math\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import flax\n",
    "from flax import nnx\n",
    "from flax.nnx.nn import initializers\n",
    "from typing import Callable\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from models import ScRRAMBLeCapsLayer\n",
    "\n",
    "from utils.activation_functions import quantized_relu_ste, squash\n",
    "from utils.loss_functions import margin_loss\n",
    "from utils import ScRRAMBLe_routing, intercore_connectivity, load_and_augment_mnist\n",
    "\n",
    "\n",
    "import tensorflow_datasets as tfds  # TFDS to download MNIST.\n",
    "import tensorflow as tf  # TensorFlow / `tf.data` operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad617c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d4116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScRRAMBLeCapsNet(nnx.Module):\n",
    "    \"\"\"\n",
    "    ScRRAMBLe CapsNet model for MNIST classification.\n",
    "\n",
    "    Notes:\n",
    "    - Currently assumes that the connection probability is the same for all the layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_vector_size: int, # size of flattened input vector\n",
    "            capsule_size: int, # size of each capsule e.g. 256 (number of columns/rows of a core)\n",
    "            receptive_field_size: int, # size of each receptive field e.g. 64 (number of columns/rows of a slot)\n",
    "            connection_probability: float, # fraction of total receptive fields on sender side that each receiving slot/receptive field takes input from\n",
    "            rngs: nnx.Rngs,\n",
    "            layer_sizes: list = [20, 10, 10], # number of capsules in each layer of the capsnet. e.g. [20, 10] means 20 capsules in layer 1 and 10 capsules in layer 2\n",
    "            activation_function: Callable = nnx.relu, # activation function to use in the network\n",
    "    ):\n",
    "        \n",
    "        self.input_vector_size = input_vector_size\n",
    "        self.capsule_size = capsule_size \n",
    "        self.receptive_field_size = receptive_field_size\n",
    "        self.rngs = rngs\n",
    "        self.connection_probability = connection_probability\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "        # calculate the effective capsules in input vector rouded to the nearest integral multiple of capsule size\n",
    "        self.input_eff_capsules = math.ceil(self.input_vector_size/self.capsule_size)\n",
    "\n",
    "        # add this element as the first element of layer_sizes\n",
    "        self.layer_sizes.insert(0, self.input_eff_capsules)\n",
    "\n",
    "        # define ScRRAMBLe capsules\n",
    "        self.scrramble_caps_layers = [ScRRAMBLeCapsLayer(\n",
    "            input_vector_size=self.capsule_size * Nci,\n",
    "            num_capsules=Nco,\n",
    "            capsule_size=self.capsule_size,\n",
    "            receptive_field_size=self.receptive_field_size,\n",
    "            connection_probability=self.connection_probability,\n",
    "            rngs=self.rngs\n",
    "        ) for Nci, Nco in zip(self.layer_sizes[:-1], self.layer_sizes[1:])]\n",
    "\n",
    "\n",
    "    def __call__(self, x:jax.Array) -> jax.Array:\n",
    "        \"\"\"\n",
    "        Forward pass through the ScRRAMBLe CapsNet\n",
    "        \"\"\"\n",
    "\n",
    "        # resize the image to be (32, 32) for MNIST\n",
    "        x = jax.image.resize(x, (x.shape[0], 32, 32, 1), method='nearest')\n",
    "\n",
    "        # flatten the first two dimensions\n",
    "        x = jnp.reshape(x, (x.shape[0], -1))\n",
    "\n",
    "        # pass the input through the layers\n",
    "        for layer in self.scrramble_caps_layers:\n",
    "            x = jax.vmap(layer, in_axes=(0,))(x)\n",
    "            x = jnp.reshape(x, (x.shape[0], -1))\n",
    "            shape_x = x.shape\n",
    "            # x = x.flatten()\n",
    "            # x = jax.vmap(self.activation_function, in_axes=(0, None, None))(x, 8, 1.0) # 8 bits, 1.0 is the max clipping threshold.\n",
    "            x = self.activation_function(x)  # Apply the activation function.\n",
    "            x = jnp.reshape(x, shape_x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ffbaa",
   "metadata": {},
   "source": [
    "## Reconstruction Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d763535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructionNetwork(nnx.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 rngs: nnx.Rngs):\n",
    "        \n",
    "        # define feedforward layers\n",
    "        self.fc1 = nnx.Linear(input_size, 5000, rngs=rngs)\n",
    "        self.fc2 = nnx.Linear(5000, 3000, rngs=rngs)\n",
    "        self.fc3 = nnx.Linear(3000, 28*28, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        x = nnx.relu(self.fc1(x))\n",
    "        x = nnx.relu(self.fc2(x))\n",
    "        x = nnx.sigmoid(self.fc3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f569c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47089fa1",
   "metadata": {},
   "source": [
    "# Load the model from saved location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81717eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"/local_disk/vikrant/scrramble/models/sscamble_mnist_capsnet_capsules70_acc_99_2025-07-24.pkl\"\n",
    "training_metrics_path = f\" /local_disk/vikrant/scrramble/logs/sscamble_mnist_capsnet_capsules70_acc_99_2025-07-24.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d32b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rngs = nnx.Rngs(params=0, activations=1, permute=5, default=2341)\n",
    "model = ScRRAMBLeCapsNet(\n",
    "    input_vector_size=1024,\n",
    "    capsule_size=256,\n",
    "    receptive_field_size=64,\n",
    "    connection_probability=0.2,\n",
    "    rngs=rngs,\n",
    "    layer_sizes=[60, 10],  # 20 capsules in the first layer and (translates to sum of layer_sizes cores total)\n",
    "    activation_function=nnx.relu\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f556fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_state = pickle.load(open(model_path, \"rb\"))\n",
    "graphdef, old_state = nnx.split(model)\n",
    "model = nnx.merge(graphdef, loaded_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d996cd1a",
   "metadata": {},
   "source": [
    "## Let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad727dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1753407467.260161 3380783 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/local_disk/vikrant/datasets\"\n",
    "dataset_dict = {\n",
    "    'batch_size': 100, # 64 is a good batch size for MNIST\n",
    "    'train_steps': int(2e4), # run for longer, 20000 is good!\n",
    "    'binarize': True, \n",
    "    'greyscale': True,\n",
    "    'data_dir': data_dir,\n",
    "    'seed': 101,\n",
    "    'shuffle_buffer': 1024,\n",
    "    'threshold' : 0.5, # binarization threshold, not to be confused with the threshold in the model\n",
    "    'eval_every': 1000,\n",
    "}\n",
    "\n",
    "# loading the dataset\n",
    "train_ds, valid_ds, test_ds = load_and_augment_mnist(\n",
    "    batch_size=dataset_dict['batch_size'],\n",
    "    train_steps=dataset_dict['train_steps'],\n",
    "    data_dir=dataset_dict['data_dir'],\n",
    "    seed=dataset_dict['seed'],\n",
    "    shuffle_buffer=dataset_dict['shuffle_buffer'],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e046ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 18:42:20.224845: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# test a batch\n",
    "model.eval()\n",
    "batch = next(iter(test_ds.as_numpy_iterator()))\n",
    "out = model(batch['image'])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9d38a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[2 0 4 8 7 6 0 6 3 1]\n",
      "[2 0 4 8 7 6 0 6 3 1]\n"
     ]
    }
   ],
   "source": [
    "# writing the pred function\n",
    "@nnx.jit\n",
    "def pred_step(model: ScRRAMBLeCapsNet, batch):\n",
    "    \"\"\"\n",
    "    Prediction step for the ScRRAMBLe CapsNet model.\n",
    "    \"\"\"\n",
    "    # Forward pass through the model\n",
    "    out = model(batch['image'])\n",
    "    \n",
    "    # reshape\n",
    "    out = jnp.reshape(out, (out.shape[0], 10, -1))\n",
    "\n",
    "    # take vector sizes along hte final dimension\n",
    "    out = jnp.linalg.norm(out, axis=-1)\n",
    "\n",
    "    # take argmax along the second dimension to get the predicted class\n",
    "    out = jnp.argmax(out, axis=-1)\n",
    "    \n",
    "    return out\n",
    "\n",
    "# test\n",
    "pred = pred_step(model, batch)\n",
    "print(pred.shape)\n",
    "print(pred[:10])  # Print the first 10 predictions\n",
    "print(batch['label'][:10])  # Print the first 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a516b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
